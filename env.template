# AI Cover Letter Generator - Environment Configuration Template
# Copy this file to .env and fill in your values

# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================
# SQLite database file (default: creates ai_cover_letter.db in the app directory)
DATABASE_URL=sqlite:///./ai_cover_letter.db

# For PostgreSQL (optional - uncomment and configure if using PostgreSQL)
# DATABASE_URL=postgresql://username:password@localhost:5432/ai_cover_letter

# =============================================================================
# LLM SERVICE CONFIGURATION
# =============================================================================
# Default LLM provider (ollama, openai, anthropic)
LLM_PROVIDER=ollama

# Ollama configuration (local - no API key required)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2:latest
# Timeout for Ollama requests (seconds) - local models can be slow
OLLAMA_TIMEOUT=120

# OpenAI configuration (requires API key)
# Get API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4
# Timeout for OpenAI requests (seconds)
OPENAI_TIMEOUT=60

# Anthropic Claude configuration (requires API key)
# Get API key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_MODEL=claude-3-sonnet-20240229
# Timeout for Anthropic requests (seconds) - Claude models can be slow
ANTHROPIC_TIMEOUT=90

# =============================================================================
# COMPANY RESEARCH API KEYS
# =============================================================================
# Tavily AI (recommended for company research)
# Get free API key from: https://tavily.com/
TAVILY_API_KEY=tvly-your_tavily_api_key_here

# Google AI (requires API key)
# Get API key from: https://makersuite.google.com/app/apikey
GOOGLE_API_KEY=your_google_api_key_here

# Brave Search (optional - works without API key, but better with one)
# Get API key from: https://api.search.brave.com/
BRAVE_API_KEY=your_brave_api_key_here

# OpenAI (can be used for both LLM generation and company research)
# Get API key from: https://platform.openai.com/api-keys
# Note: OpenAI can be used for both cover letter generation and company research
OPENAI_API_KEY=your_openai_api_key_here

# =============================================================================
# SELF-HOSTED SEARCH ENGINES (Optional)
# =============================================================================
# YaCy search engine URL (if self-hosted)
# Install YaCy: https://yacy.net/
YACY_URL=http://localhost:8090

# SearXNG search engine URL (if self-hosted)
# Install SearXNG: https://docs.searxng.org/
SEARXNG_URL=http://localhost:8080

# =============================================================================
# DOCUMENT PARSING CONFIGURATION
# =============================================================================
# Maximum file size for uploads (in bytes, default: 10MB)
MAX_FILE_SIZE=10485760

# Supported file types for document parsing
SUPPORTED_FILE_TYPES=.pdf,.docx,.doc,.txt,.rtf

# =============================================================================
# LINKEDIN INTEGRATION (Optional)
# =============================================================================
# LinkedIn credentials for profile scraping
# Note: Use with caution and respect LinkedIn's terms of service
LINKEDIN_EMAIL=your_linkedin_email@example.com
LINKEDIN_PASSWORD=your_linkedin_password

# =============================================================================
# EXPORT CONFIGURATION
# =============================================================================
# PDF export settings
PDF_FONT_SIZE=12
PDF_MARGIN=1.0

# DOCX export settings
DOCX_FONT_NAME=Calibri
DOCX_FONT_SIZE=11

# =============================================================================
# RATE LIMITING AND PERFORMANCE
# =============================================================================
# Rate limiting for API calls (requests per minute)
DUCKDUCKGO_RATE_LIMIT=10
GOOGLE_RATE_LIMIT=100
TAVILY_RATE_LIMIT=50
BRAVE_RATE_LIMIT=20
YACY_RATE_LIMIT=30
SEARXNG_RATE_LIMIT=30

# =============================================================================
# SECURITY AND PRIVACY
# =============================================================================
# Secret key for session management (generate a random string)
SECRET_KEY=your_secret_key_here_generate_random_string

# Enable/disable debug mode
DEBUG=False

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================
# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# Log file path (optional)
LOG_FILE=./logs/ai_cover_letter.log

# =============================================================================
# WEB INTERFACE CONFIGURATION
# =============================================================================
# Host and port for the web interface
HOST=127.0.0.1
PORT=8000

# Enable/disable auto-reload for development
AUTO_RELOAD=True

# =============================================================================
# BATCH PROCESSING CONFIGURATION
# =============================================================================
# Default delay between batch requests (seconds)
DEFAULT_BATCH_DELAY=3

# Maximum number of concurrent batch requests
MAX_CONCURRENT_BATCH_REQUESTS=5

# =============================================================================
# RAG (Retrieval-Augmented Generation) CONFIGURATION
# =============================================================================
# Embedding model for RAG (if using local embeddings)
EMBEDDING_MODEL=all-MiniLM-L6-v2

# Number of relevant chunks to retrieve for RAG
RAG_CHUNK_COUNT=5

# Chunk size for document splitting
RAG_CHUNK_SIZE=1000

# Document weighting configuration
# Base weight for uploaded documents (default: 1.0)
DOCUMENT_BASE_WEIGHT=1.0

# Recency weighting period in days (default: 365 days)
# Documents older than this period get minimum weight
DOCUMENT_RECENCY_PERIOD_DAYS=365

# Minimum weight multiplier for old documents (default: 0.1)
# Documents older than the recency period get this minimum weight
DOCUMENT_MIN_WEIGHT_MULTIPLIER=0.1

# Enable/disable recency weighting (default: true)
DOCUMENT_RECENCY_WEIGHTING_ENABLED=true

# Document type specific weights (higher values = more important for RAG)
# CV documents get this weight multiplier (most important)
CV_WEIGHT_MULTIPLIER=2.0

# Cover letter documents get this weight multiplier (very important)
COVER_LETTER_WEIGHT_MULTIPLIER=1.8

# LinkedIn documents get this weight multiplier (moderately important)
LINKEDIN_WEIGHT_MULTIPLIER=1.2

# Other document types get this weight multiplier (least important)
OTHER_DOCUMENT_WEIGHT_MULTIPLIER=0.8

# =============================================================================
# NOTES AND TIPS
# =============================================================================
# 1. Only fill in the API keys you plan to use
# 2. For local development, you only need OLLAMA_BASE_URL and OLLAMA_MODEL
# 3. Tavily AI is recommended for company research (free tier available)
# 4. Brave Search works without API key but is better with one
# 5. Self-hosted search engines (YaCy, SearXNG) are optional
# 6. Generate a random SECRET_KEY for production use
# 7. Set DEBUG=False in production
# 8. Create the logs directory if using LOG_FILE
#
# Example minimal .env for local development:
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_MODEL=llama3.2:latest
# SECRET_KEY=your_random_secret_key_here
# DEBUG=True 